{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9058174",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2. Предварительная обработка текстовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3b556",
   "metadata": {},
   "source": [
    "## Цель работы\n",
    "Получить практические навыки обработки текстовых данных в среде Jupiter Notebook. Научиться проводить предварительную обработку текстовых данных и выявлять параметры обработки, позволяющие добиться наилучшей точности классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd34d0",
   "metadata": {},
   "source": [
    "## Выполнение работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcb349",
   "metadata": {},
   "source": [
    "### 1. В среде Jupyter Notebook создать новый ноутбук (Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd132117",
   "metadata": {},
   "source": [
    "### 2. Импортировать необходимые для работы библиотеки и модули\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1e59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5320669",
   "metadata": {},
   "source": [
    "### 3. Загрузить обучающую и экзаменационную выборку в соответствие с вариантом\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a10c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['misc.forsale','sci.med','talk.religion.misc'] \n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=23, categories = categories, remove = remove )\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=23, categories = categories, remove = remove )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5f10e",
   "metadata": {},
   "source": [
    "### 4. Вывести на экран по одному-два документа каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52bf4c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misc.forsale\n",
      "sci.med\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "print (twenty_train.target_names[twenty_train.target[1]])\n",
    "print (twenty_train.target_names[twenty_train.target[2]])\n",
    "print (twenty_train.target_names[twenty_train.target[7]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905445a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One way ticket (return leg of roundtrip ticket) for female traveler\n",
      "\n",
      "\n",
      "\n",
      "San Francisco ==> St. Louis ==> Philadelphia\n",
      "\n",
      "\n",
      "May 21, 1993 (Friday)  leaves SFO     10:25 am\n",
      "                       arrives Phila.  8:43 pm\n",
      "\n",
      "\n",
      "\n",
      ".............$150   or best offer\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9495282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L(>  |JB>  1) Ron...what do YOU consider to be \"proper channels\"...\n",
      "L(>  \n",
      "L(>  |  I'm glad it caught your eye. That's the purpose of this forum to\n",
      "L(>  | educate those, eager to learn, about the facts of life. That phrase\n",
      "L(>  | is used to bridle the frenzy of all the would-be respondents, who\n",
      "L(>  | otherwise would feel being left out as the proper authorities to be\n",
      "L(>  | consulted on that topic. In short, it means absolutely nothing.\n",
      "L(>  \n",
      "L(>  An apt description of the content of just about all Ron Roth's \n",
      "L(>  posts to date.  At least there's entertainment value (though it \n",
      "L(>  is diminishing).\n",
      "\n",
      "     Well, that's easy for *YOU* to say.  All *YOU* have to do is sit \n",
      "     back, soak it all in, try it out on your patients, and then brag\n",
      "     to all your colleagues about that incredibly success rate you're\n",
      "     having all of a sudden...\n",
      "\n",
      "     --Ron--\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99748034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Finally, brethern, whatever is true, whatever is honorable, whatever is\n",
      "right, whatever is pure, whatever is lovely, whatever is of good repute,\n",
      "if there is any excellence and if anything worthy of praise, let your\n",
      "mind dwell on these things.\"  Phil. 4:8.\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a7a78",
   "metadata": {},
   "source": [
    "### 5. Применить стемминг, записав обработанные выборки (тестовую и обучающую) в новые переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c346caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1556/1556 [00:08<00:00, 173.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1037/1037 [00:08<00:00, 126.49it/s]\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer() \n",
    "def stemming(text: str) -> str:\n",
    "  words = []\n",
    "  for word in word_tokenize(text):\n",
    "    words.append(porter_stemmer.stem(word.lower()))\n",
    "  return ' '.join(words) \n",
    "def stemming_dataset(dataset: list) -> list: \n",
    "  resulting_list = []\n",
    "  for example in tqdm(dataset): \n",
    "    resulting_list.append(stemming(example))\n",
    "  return resulting_list \n",
    "stem_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=23, categories = categories, remove = remove )\n",
    "stem_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=23, categories = categories, remove = remove )\n",
    "stem_train['data_stem'] = stemming_dataset(stem_train['data']) \n",
    "stem_test['data_stem'] = stemming_dataset(stem_test['data']) \n",
    "del stem_train['data']\n",
    "del stem_test['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22cd61",
   "metadata": {},
   "source": [
    "### 6. Провести векторизацию выборки: \n",
    "- Векторизовать обучающую и тестовую выборки простым подсчетом слов (CountVectorizer) \n",
    "- Вывести и проанализировать первые 20 наиболее частотных слов всей выборки и каждого класса по-отдельности. \n",
    "- Рассчитать сходство по коэффициенту Жаккара между тремя классами \n",
    "- Применить процедуру отсечения стоп-слов и повторить пункты 2,3. \n",
    "- Провести пункты 1-3 для обучающей и тестовой выборки, для которой проведена процедура стемминга. \n",
    "- Векторизовать выборки с помощью TfidfTransformer (с использованием TF и TF-IDF взвешиваний)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3796c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(set(list1)) + len(set(list2))) - intersection\n",
    "    return float(intersection) / union\n",
    "def SortbyTF(inputStr):\n",
    "    return inputStr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c884351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11301), ('of', 6613), ('to', 6208), ('and', 5710), ('in', 3962), ('is', 3857), ('that', 3485), ('it', 2943), ('for', 2894), ('you', 2402), ('this', 1766), ('are', 1753), ('with', 1736), ('not', 1711), ('have', 1632), ('be', 1555), ('or', 1504), ('as', 1433), ('on', 1314), ('but', 1143)] \n",
      "\n",
      "[('the', 7706), ('of', 4314), ('to', 4227), ('and', 3922), ('in', 2670), ('is', 2596), ('that', 2302), ('for', 2017), ('it', 1819), ('you', 1541), ('have', 1230), ('with', 1157), ('are', 1149), ('this', 1149), ('not', 1084), ('or', 1009), ('be', 1002), ('as', 932), ('on', 926), ('if', 790)]\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features = 10000)\n",
    "vect.fit(twenty_train.data)\n",
    "\n",
    "train_data = vect.transform(twenty_train.data)\n",
    "test_data = vect.transform(twenty_test.data)\n",
    "\n",
    "train_vec = list(zip(vect.get_feature_names_out(), np.ravel(train_data.sum(axis=0))))\n",
    "test_vec = list(zip(vect.get_feature_names_out(), np.ravel(test_data.sum(axis=0))))\n",
    "\n",
    "train_vec.sort(key=SortbyTF, reverse = True)\n",
    "test_vec.sort(key=SortbyTF, reverse = True)\n",
    "print (train_vec[:20],'\\n')\n",
    "print (test_vec[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2b635ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = {i: twenty_train['target_names'][i] for i in range(len(twenty_train['target_names']))}\n",
    "for i in range(3):\n",
    "  twenty_train[class_name[i]] = [twenty_train['data'][j] for j in range(len(twenty_train['data']))\\\n",
    "                                 if twenty_train['target'][j] == i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee250235",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `forsale`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ccadd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1488), ('for', 1157), ('and', 1081), ('to', 967), ('of', 755), ('in', 645), ('00', 617), ('it', 513), ('is', 510), ('you', 477), ('with', 452), ('or', 430), ('have', 378), ('are', 308), ('all', 294), ('if', 283), ('new', 278), ('this', 274), ('that', 249), ('sale', 247)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaasd\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data_1 = vect.transform(twenty_train[class_name[0]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_1.sum(axis=0))))\n",
    "list1=x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeacd16a",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `med`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6caea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 5174), ('of', 3283), ('to', 2879), ('and', 2643), ('in', 1971), ('is', 1899), ('that', 1526), ('it', 1467), ('for', 1086), ('you', 863), ('this', 852), ('are', 812), ('be', 787), ('with', 776), ('not', 730), ('have', 700), ('or', 648), ('on', 635), ('as', 624), ('but', 530)]\n"
     ]
    }
   ],
   "source": [
    "train_data_2 = vect.transform(twenty_train[class_name[1]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_2.sum(axis=0))))\n",
    "list2=x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33775035",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `religion`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0fb29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4639), ('of', 2575), ('to', 2362), ('and', 1986), ('that', 1710), ('is', 1448), ('in', 1346), ('you', 1062), ('it', 963), ('not', 785), ('for', 651), ('as', 642), ('this', 640), ('are', 633), ('be', 573), ('have', 554), ('with', 508), ('was', 486), ('he', 470), ('they', 445)]\n"
     ]
    }
   ],
   "source": [
    "train_data_3 = vect.transform(twenty_train[class_name[2]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_3.sum(axis=0))))\n",
    "list3=x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f560b81",
   "metadata": {},
   "source": [
    "**Рассчёт сходства по коэффициенту Жаккара между тремя классами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46176090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициент сходства между классом 0 и 1:  0.07764426962659626\n",
      "Коэффициент сходства между классом 1 и 2:  0.0949904188338352\n",
      "Коэффициент сходства между классом 0 и 2:  0.1367511651699443\n"
     ]
    }
   ],
   "source": [
    "print (\"Коэффициент сходства между классом 0 и 1: \", jaccard_similarity(list1, list2))\n",
    "print (\"Коэффициент сходства между классом 1 и 2: \", jaccard_similarity(list2, list3))\n",
    "print (\"Коэффициент сходства между классом 0 и 2: \", jaccard_similarity(list1, list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ca9c4",
   "metadata": {},
   "source": [
    "**Применение процедуры отсечения стоп-слов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01522b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features = 10000, stop_words = 'english') \n",
    "vect.fit(twenty_train.data)\n",
    "train_data_4 = vect.transform(twenty_train.data) \n",
    "test_data_4 = vect.transform(twenty_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db7192",
   "metadata": {},
   "source": [
    "**Вывод наиболее частых слов для всей выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfa05a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00', 640), ('people', 517), ('new', 504), ('edu', 502), ('don', 467), ('like', 461), ('good', 420), ('just', 417), ('know', 394), ('10', 358), ('use', 356), ('god', 338), ('time', 336), ('think', 328), ('does', 313), ('20', 285), ('used', 275), ('50', 261), ('com', 259), ('jesus', 258)]\n"
     ]
    }
   ],
   "source": [
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_4.sum(axis=0))))\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d365c",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `forsale`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b609322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00', 617), ('new', 278), ('sale', 247), ('50', 228), ('10', 214), ('dos', 201), ('offer', 195), ('shipping', 180), ('20', 168), ('price', 164), ('25', 155), ('15', 153), ('condition', 151), ('good', 146), ('used', 130), ('like', 129), ('edu', 128), ('asking', 121), ('mail', 121), ('interested', 120)]\n"
     ]
    }
   ],
   "source": [
    "train_data_1 = vect.transform(twenty_train[class_name[0]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_1.sum(axis=0))))\n",
    "list1=x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829fb1cc",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `med`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a5a9f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('edu', 354), ('don', 230), ('people', 221), ('health', 217), ('use', 216), ('medical', 206), ('like', 201), ('know', 191), ('com', 190), ('time', 180), ('just', 174), ('patients', 163), ('new', 162), ('think', 153), ('disease', 146), ('good', 143), ('msg', 143), ('food', 142), ('years', 139), ('doctor', 133)]\n"
     ]
    }
   ],
   "source": [
    "train_data_2 = vect.transform(twenty_train[class_name[1]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_2.sum(axis=0))))\n",
    "list2=x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728acce4",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `religion`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ee8d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('god', 329), ('people', 267), ('jesus', 256), ('don', 162), ('bible', 160), ('just', 159), ('christian', 151), ('think', 151), ('know', 149), ('say', 149), ('does', 147), ('did', 132), ('good', 131), ('like', 131), ('life', 118), ('way', 118), ('believe', 117), ('said', 103), ('point', 101), ('time', 99)]\n"
     ]
    }
   ],
   "source": [
    "train_data_3 = vect.transform(twenty_train[class_name[2]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_3.sum(axis=0))))\n",
    "list3=x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da90271",
   "metadata": {},
   "source": [
    "**Рассчёт сходства по коэффициенту Жаккара между тремя классами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40edece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициент сходства между классом 0 и 1:  0.08166576527852894\n",
      "Коэффициент сходства между классом 1 и 2:  0.10083663584324086\n",
      "Коэффициент сходства между классом 0 и 2:  0.14311842706904435\n"
     ]
    }
   ],
   "source": [
    "print (\"Коэффициент сходства между классом 0 и 1: \", jaccard_similarity(list1, list2))\n",
    "print (\"Коэффициент сходства между классом 1 и 2: \", jaccard_similarity(list2, list3))\n",
    "print (\"Коэффициент сходства между классом 0 и 2: \", jaccard_similarity(list1, list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9cf4e",
   "metadata": {},
   "source": [
    "**Повторение после применения стемминга**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b780fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features = 10000) \n",
    "vect.fit(stem_train.data_stem)\n",
    "train_data_stem = vect.transform(stem_train.data_stem) \n",
    "test_data_stem = vect.transform(stem_test.data_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354122ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 11298), ('of', 6613), ('to', 6208), ('and', 5712), ('in', 3964), ('is', 3922), ('that', 3488), ('it', 3111), ('for', 2894), ('you', 2401), ('are', 1786), ('not', 1780), ('have', 1774), ('thi', 1770), ('be', 1764), ('with', 1737), ('or', 1504), ('as', 1431), ('do', 1386), ('on', 1320)]\n"
     ]
    }
   ],
   "source": [
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_stem.sum(axis=0))))\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7996836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = {i: stem_train['target_names'][i] for i in range (len(stem_train['target_names']))}\n",
    "for i in range(3):\n",
    "  stem_train[class_name[i]] = [stem_train['data_stem'][j] for j in range(len(stem_train['data_stem']))\\\n",
    "                               if stem_train['target'][j] == i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cddb05",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `forsale` при стемминге**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0099f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1486), ('for', 1157), ('and', 1081), ('to', 967), ('of', 755), ('in', 647), ('00', 617), ('it', 532), ('is', 516), ('you', 477), ('with', 453), ('or', 430), ('have', 385), ('do', 318), ('are', 310), ('all', 292), ('if', 283), ('new', 278), ('thi', 274), ('will', 253)]\n"
     ]
    }
   ],
   "source": [
    "train_data_stem_1 = vect.transform(stem_train[class_name[0]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_stem_1.sum(axis=0))))\n",
    "list1 = x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eaa9b0",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `med` при стемминге**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c06695ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 5173), ('of', 3283), ('to', 2879), ('and', 2644), ('in', 1971), ('is', 1936), ('it', 1539), ('that', 1527), ('for', 1086), ('be', 865), ('you', 863), ('thi', 853), ('are', 828), ('have', 786), ('with', 776), ('not', 749), ('or', 648), ('on', 637), ('as', 624), ('do', 552)]\n"
     ]
    }
   ],
   "source": [
    "train_data_stem_2 = vect.transform(stem_train[class_name[1]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_stem_2.sum(axis=0))))\n",
    "list2 = x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8e6336",
   "metadata": {},
   "source": [
    "**Наиболее частые слова в классе `religion` при стемминге**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47a6bbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4639), ('of', 2575), ('to', 2362), ('and', 1987), ('that', 1711), ('is', 1470), ('in', 1346), ('you', 1061), ('it', 1040), ('not', 829), ('be', 696), ('for', 651), ('are', 648), ('thi', 643), ('as', 640), ('have', 603), ('do', 516), ('with', 508), ('wa', 493), ('he', 470)]\n"
     ]
    }
   ],
   "source": [
    "train_data_stem_3 = vect.transform(stem_train[class_name[2]]) \n",
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data_stem_3.sum(axis=0))))\n",
    "list3 = x\n",
    "x.sort(key=SortbyTF, reverse = True) \n",
    "print (x[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a7ab5d",
   "metadata": {},
   "source": [
    "**Рассчёт сходства по коэффициенту Жаккара между тремя классами при стемминге**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d3fee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициент сходства между классом 0 и 1:  0.08902804247209366\n",
      "Коэффициент сходства между классом 1 и 2:  0.113895850737956\n",
      "Коэффициент сходства между классом 0 и 2:  0.15620302925193663\n"
     ]
    }
   ],
   "source": [
    "print (\"Коэффициент сходства между классом 0 и 1: \", jaccard_similarity(list1, list2))\n",
    "print (\"Коэффициент сходства между классом 1 и 2: \", jaccard_similarity(list2, list3))\n",
    "print (\"Коэффициент сходства между классом 0 и 2: \", jaccard_similarity(list1, list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b963504",
   "metadata": {},
   "source": [
    "**Векторизовать выборки с помощью TfidfTransformer (с использованием TF и TF-IDF взвешиваний).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3685864",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf = True).fit(train_data)\n",
    "train_data_tfidf = tfidf.transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad0a88",
   "metadata": {},
   "source": [
    "### 7. Используя конвейер (Pipeline) реализовать модель Наивного Байесовского классификатора и выявить на основе показателей качества (значения полноты, точности, f1-меры и аккуратности), какая предварительная обработка данных обеспечит наилучшие результаты классификации. Должны быть исследованы следующие характеристики:\n",
    "\n",
    "- Наличие \\ отсутствие стемминга\n",
    "- Отсечение \\ не отсечение стоп-слов\n",
    "- Взвешивание: Count, TF, TF-IDF\n",
    "- Количество информативных терминов (max_features) - исследовать 5 значений в диапазоне от 100 до общего количества слов в выборке.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d70fd",
   "metadata": {},
   "source": [
    "**Взвешивание Count при отсутствии стемминга и отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d126b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.90549662487946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94       390\n",
      "           1       0.89      0.91      0.90       396\n",
      "           2       0.82      0.90      0.86       251\n",
      "\n",
      "    accuracy                           0.91      1037\n",
      "   macro avg       0.90      0.90      0.90      1037\n",
      "weighted avg       0.91      0.91      0.91      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000)), ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target) \n",
    "prediction = text_clf.predict(twenty_test.data)\n",
    "print('Accuracy score: ', accuracy_score(prediction, twenty_test.target)) \n",
    "print(classification_report(twenty_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c7bc0",
   "metadata": {},
   "source": [
    "**Взвешивание Count при наличии стемминга и отсутствии отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0725350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9112825458052073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       390\n",
      "           1       0.89      0.92      0.91       396\n",
      "           2       0.84      0.88      0.86       251\n",
      "\n",
      "    accuracy                           0.91      1037\n",
      "   macro avg       0.91      0.91      0.91      1037\n",
      "weighted avg       0.91      0.91      0.91      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000)), ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd15ff",
   "metadata": {},
   "source": [
    "**Взвешивание Count при наличии стемминга и отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16c2576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9170684667309547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       390\n",
      "           1       0.90      0.93      0.91       396\n",
      "           2       0.87      0.88      0.88       251\n",
      "\n",
      "    accuracy                           0.92      1037\n",
      "   macro avg       0.91      0.91      0.91      1037\n",
      "weighted avg       0.92      0.92      0.92      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000, stop_words = 'english')), ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626bd8c6",
   "metadata": {},
   "source": [
    "**Взвешивание Count при наличии стемминга и отсечения стоп-слов; число информативных признаков 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a37b4737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7984570877531341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       390\n",
      "           1       0.74      0.83      0.78       396\n",
      "           2       0.74      0.69      0.71       251\n",
      "\n",
      "    accuracy                           0.80      1037\n",
      "   macro avg       0.80      0.79      0.79      1037\n",
      "weighted avg       0.80      0.80      0.80      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 100, stop_words = 'english')), ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692a69b",
   "metadata": {},
   "source": [
    "**Взвешивание Count при наличии стемминга и отсечения стоп-слов; число информативных признаков 1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da409a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.875602700096432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       390\n",
      "           1       0.86      0.86      0.86       396\n",
      "           2       0.80      0.84      0.82       251\n",
      "\n",
      "    accuracy                           0.88      1037\n",
      "   macro avg       0.87      0.87      0.87      1037\n",
      "weighted avg       0.88      0.88      0.88      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 1000, stop_words = 'english')), ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4687f9f",
   "metadata": {},
   "source": [
    "**Взвешивание Count при наличии стемминга и отсечения стоп-слов; число информативных признаков 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ece3c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9132111861137898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       390\n",
      "           1       0.89      0.92      0.91       396\n",
      "           2       0.87      0.88      0.87       251\n",
      "\n",
      "    accuracy                           0.91      1037\n",
      "   macro avg       0.91      0.91      0.91      1037\n",
      "weighted avg       0.91      0.91      0.91      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 5000, stop_words = 'english')), ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338f371",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при отсутствии стемминга и отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac6375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8187078109932497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       390\n",
      "           1       0.69      0.97      0.81       396\n",
      "           2       0.95      0.44      0.60       251\n",
      "\n",
      "    accuracy                           0.82      1037\n",
      "   macro avg       0.87      0.77      0.78      1037\n",
      "weighted avg       0.86      0.82      0.81      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000)), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target) \n",
    "prediction = text_clf.predict(twenty_test.data)\n",
    "print('Accuracy score: ', accuracy_score(prediction, twenty_test.target)) \n",
    "print(classification_report(twenty_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf2f1b",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсутствии отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bed02e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8177434908389586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       390\n",
      "           1       0.69      0.98      0.81       396\n",
      "           2       0.95      0.41      0.57       251\n",
      "\n",
      "    accuracy                           0.82      1037\n",
      "   macro avg       0.88      0.77      0.78      1037\n",
      "weighted avg       0.86      0.82      0.80      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000)), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eedff9",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99c785dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8736740597878495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       390\n",
      "           1       0.79      0.96      0.86       396\n",
      "           2       0.95      0.64      0.76       251\n",
      "\n",
      "    accuracy                           0.87      1037\n",
      "   macro avg       0.90      0.85      0.86      1037\n",
      "weighted avg       0.89      0.87      0.87      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b7eb7",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8cd4d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7955641272902604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       390\n",
      "           1       0.71      0.88      0.79       396\n",
      "           2       0.82      0.57      0.67       251\n",
      "\n",
      "    accuracy                           0.80      1037\n",
      "   macro avg       0.81      0.77      0.78      1037\n",
      "weighted avg       0.81      0.80      0.79      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 100, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e60b534",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ab84942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8727097396335584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       390\n",
      "           1       0.83      0.91      0.87       396\n",
      "           2       0.89      0.74      0.80       251\n",
      "\n",
      "    accuracy                           0.87      1037\n",
      "   macro avg       0.88      0.86      0.86      1037\n",
      "weighted avg       0.87      0.87      0.87      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 1000, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a35108",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3a18cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8823529411764706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       390\n",
      "           1       0.81      0.94      0.87       396\n",
      "           2       0.95      0.69      0.79       251\n",
      "\n",
      "    accuracy                           0.88      1037\n",
      "   macro avg       0.90      0.86      0.87      1037\n",
      "weighted avg       0.89      0.88      0.88      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 5000, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6f68a",
   "metadata": {},
   "source": [
    "**Взвешивание TF при отсутствии стемминга и отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35625462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.712632594021215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       390\n",
      "           1       0.57      0.99      0.73       396\n",
      "           2       1.00      0.04      0.08       251\n",
      "\n",
      "    accuracy                           0.71      1037\n",
      "   macro avg       0.85      0.63      0.57      1037\n",
      "weighted avg       0.83      0.71      0.64      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000)), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target) \n",
    "prediction = text_clf.predict(twenty_test.data)\n",
    "print('Accuracy score: ', accuracy_score(prediction, twenty_test.target)) \n",
    "print(classification_report(twenty_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9551a",
   "metadata": {},
   "source": [
    "**Взвешивание TF при наличии стемминга и отсутствии отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "196c1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7184185149469624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.93       390\n",
      "           1       0.58      0.99      0.73       396\n",
      "           2       1.00      0.05      0.09       251\n",
      "\n",
      "    accuracy                           0.72      1037\n",
      "   macro avg       0.85      0.64      0.58      1037\n",
      "weighted avg       0.83      0.72      0.65      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000)), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a3b16",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 10000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76eeae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8505303760848602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       390\n",
      "           1       0.75      0.96      0.84       396\n",
      "           2       0.96      0.57      0.71       251\n",
      "\n",
      "    accuracy                           0.85      1037\n",
      "   macro avg       0.88      0.82      0.83      1037\n",
      "weighted avg       0.87      0.85      0.84      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 10000, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5ff9d",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "106ef4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7888138862102217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       390\n",
      "           1       0.70      0.89      0.78       396\n",
      "           2       0.82      0.54      0.65       251\n",
      "\n",
      "    accuracy                           0.79      1037\n",
      "   macro avg       0.81      0.76      0.77      1037\n",
      "weighted avg       0.80      0.79      0.78      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 100, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d43cc",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 1000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fa86a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8601735776277725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       390\n",
      "           1       0.81      0.89      0.85       396\n",
      "           2       0.88      0.72      0.79       251\n",
      "\n",
      "    accuracy                           0.86      1037\n",
      "   macro avg       0.87      0.84      0.85      1037\n",
      "weighted avg       0.86      0.86      0.86      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(max_features= 1000, stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = False)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689be74b",
   "metadata": {},
   "source": [
    "**Взвешивание TF-IDF при наличии стемминга и отсечения стоп-слов; число информативных признаков 5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e25039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8688524590163934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       390\n",
      "           1       0.77      0.97      0.86       396\n",
      "           2       0.96      0.59      0.73       251\n",
      "\n",
      "    accuracy                           0.87      1037\n",
      "   macro avg       0.90      0.84      0.85      1037\n",
      "weighted avg       0.89      0.87      0.86      1037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words = 'english')), \n",
    "                     ('tfidf', TfidfTransformer(use_idf = True)), \n",
    "                     ('clf', MultinomialNB ()),])\n",
    "text_clf = text_clf.fit(stem_train.data_stem, stem_train.target) \n",
    "prediction = text_clf.predict(stem_test.data_stem)\n",
    "print('Accuracy score: ', accuracy_score(prediction, stem_test.target)) \n",
    "print(classification_report(stem_test.target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76959980",
   "metadata": {},
   "source": [
    "### 8. По результатам классификации занести в отчет выводы о влиянии каждого из этапов предобработки данных (наличие стемминга, взвешивание терминов, стоп-слова, количество информативных терминов) и о наиболее подходящей их комбинации. Объяснить различия (если имеются) в качестве классификации разных классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f2f67",
   "metadata": {},
   "source": [
    "| Взвешивание | Стемминг | Отсечение стоп-слов | Число информативных признаков | Accuracy |      | Precision |      |      | Recall |      |      | f1-score |      |\n",
    "|:-----------:|:--------:|:-------------------:|:-----------------------------:|:--------:|:----:|:---------:|:----:|:----:|:------:|:----:|:----:|:--------:|:----:|\n",
    "|             |          |                     |                               |          |   0  |     1     |   2  |   0  |    1   |   2  |   0  |     1    |   2  |\n",
    "|    Count    |     -    |          -          |             10000             |   0.905  | 0.99 |    0.89   | 0.82 | 0.91 |  0.91  |  0.9 | 0.94 |    0.9   | 0.86 |\n",
    "|    Count    |     +    |          -          |             10000             |   0.911  | 0.99 |    0.89   | 0.84 | 0.92 |  0.92  | 0.88 | 0.95 |   0.91   | 0.86 |\n",
    "|    Count    |     +    |          +          |              100              |   0.798  | 0.91 |    0.74   | 0.74 | 0.84 |  0.83  | 0.69 | 0.87 |   0.78   | 0.71 |\n",
    "|    Count    |     +    |          +          |              1000             |   0.876  | 0.94 |    0.86   |  0.8 | 0.91 |  0.86  | 0.84 | 0.93 |   0.86   | 0.82 |\n",
    "|    Count    |     +    |          +          |              5000             |   0.913  | 0.96 |    0.89   | 0.87 | 0.93 |  0.92  | 0.88 | 0.95 |   0.91   | 0.87 |\n",
    "|    Count    |     +    |          +          |             10000             |   0.917  | 0.97 |    0.9    | 0.87 | 0.93 |  0.93  | 0.88 | 0.95 |   0.91   | 0.88 |\n",
    "|    TF-IDF   |     -    |          -          |             10000             |   0.819  | 0.97 |    0.69   | 0.95 | 0.91 |  0.97  | 0.44 | 0.94 |   0.81   |  0.6 |\n",
    "|    TF-IDF   |     +    |          -          |             10000             |   0.818  | 0.99 |    0.69   | 0.95 | 0.91 |  0.98  | 0.41 | 0.95 |   0.81   | 0.57 |\n",
    "|    TF-IDF   |     +    |          +          |              100              |   0.796  |  0.9 |    0.71   | 0.82 | 0.85 |  0.88  | 0.57 | 0.87 |   0.79   | 0.67 |\n",
    "|    TF-IDF   |     +    |          +          |              1000             |   0.873  | 0.92 |    0.83   | 0.89 | 0.92 |  0.91  | 0.74 | 0.92 |   0.87   |  0.8 |\n",
    "|    TF-IDF   |     +    |          +          |              5000             |   0.882  | 0.94 |    0.81   | 0.95 | 0.95 |  0.94  | 0.69 | 0.94 |   0.87   | 0.79 |\n",
    "|    TF-IDF   |     +    |          +          |             10000             |   0.874  | 0.95 |    0.79   | 0.95 | 0.94 |  0.96  | 0.64 | 0.94 |   0.86   | 0.76 |\n",
    "|      TF     |     -    |          -          |             10000             |   0.713  | 0.98 |    0.57   |   1  | 0.87 |  0.99  | 0.04 | 0.92 |   0.73   | 0.08 |\n",
    "|      TF     |     +    |          -          |             10000             |   0.718  | 0.98 |    0.58   |   1  | 0.87 |  0.99  | 0.05 | 0.93 |   0.73   | 0.09 |\n",
    "|      TF     |     +    |          +          |              100              |   0.789  |  0.9 |    0.7    | 0.82 | 0.85 |  0.89  | 0.54 | 0.87 |   0.78   | 0.65 |\n",
    "|      TF     |     +    |          +          |              1000             |   0.86   | 0.91 |    0.81   | 0.88 | 0.92 |  0.89  | 0.72 | 0.91 |   0.85   | 0.79 |\n",
    "|      TF     |     +    |          +          |              5000             |   0.88   | 0.94 |    0.81   | 0.95 | 0.95 |  0.94  | 0.69 | 0.94 |   0.87   | 0.79 |\n",
    "|      TF     |     +    |          +          |             10000             |   0.85   | 0.94 |    0.75   | 0.96 | 0.93 |  0.96  | 0.57 | 0.93 |   0.84   | 0.71 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccbb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
